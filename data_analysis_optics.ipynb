{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "955d7420",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9387573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# statistic libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6578013",
   "metadata": {},
   "source": [
    "# load the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf6daa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265590160</td>\n",
       "      <td>46.047611</td>\n",
       "      <td>11.126020</td>\n",
       "      <td>Volksbank</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269193707</td>\n",
       "      <td>46.074491</td>\n",
       "      <td>11.124553</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269193731</td>\n",
       "      <td>46.064718</td>\n",
       "      <td>11.123213</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288910331</td>\n",
       "      <td>46.065631</td>\n",
       "      <td>11.154994</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292015813</td>\n",
       "      <td>46.076473</td>\n",
       "      <td>11.141931</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        lat        lon             name     class\n",
       "0  265590160  46.047611  11.126020        Volksbank  economic\n",
       "1  269193707  46.074491  11.124553  Cassa di Trento  economic\n",
       "2  269193731  46.064718  11.123213  Cassa di Trento  economic\n",
       "3  288910331  46.065631  11.154994  Cassa di Trento  economic\n",
       "4  292015813  46.076473  11.141931  Cassa di Trento  economic"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('/Users/majadallacqua/Desktop/universit√†/II_sem/CSS/urban analysis/data/trento_poi_dataset.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b0d5f",
   "metadata": {},
   "source": [
    "# set the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fc9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kms_per_radian = 6371.0088\n",
    "\n",
    "# 12 is the number of districts in the city of Trento\n",
    "min_neigh = 12 - 5 # value for the city of Trento\n",
    "max_neigh = 12 + 5\n",
    "\n",
    "# subset used for each analysis\n",
    "df_eco = df[df['class']=='economic']\n",
    "df_edu = df[df['class']=='education']\n",
    "df_hea = df[df['class']=='health']\n",
    "df_cat = df[df['class']=='catering']\n",
    "df_shop = df[df['class']=='shopping']\n",
    "df_tou = df[df['class']=='tourism']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c1a29",
   "metadata": {},
   "source": [
    "# optics algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdf4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-computation of the harvesine distance since it is not available in the optics implementation\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    # Calcolo delle differenze di latitudine e longitudine\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    # Calcolo della distanza utilizzando la formula dell'Haversine\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Raggio medio della Terra in chilometri\n",
    "    distance = c * r\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c677650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's the value we want to try\n",
    "min_sample_params = [2, 3, 4, 5, 6, 7, 8, 9] # minimum number of elements nearby a point to be considered core point\n",
    "min_cluster_size_params = [2, 3, 4, 5, 6, 7, 8, 9] # min number of elements we want in each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcc654",
   "metadata": {},
   "source": [
    "## economic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf8f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optics found 7 valid results\n",
      "the result is:(2, 2, 15, 0.33823179856888613, 3.857171705632589)\n",
      "the result is:(2, 3, 10, 0.1291152788240539, 3.6313272749807126)\n",
      "the result is:(3, 2, 10, 0.17362172568474177, 4.303968956970478)\n",
      "the result is:(3, 3, 9, 0.13571308532174886, 4.931786481562657)\n",
      "the result is:(2, 4, 7, -0.02293910824390997, 5.802621109374607)\n",
      "the result is:(4, 2, 7, -0.03507645966274629, 7.389341477013563)\n",
      "the result is:(4, 3, 7, -0.03507645966274629, 7.389341477013563)\n"
     ]
    }
   ],
   "source": [
    "df_eco_rad = np.array(np.radians(df_eco[['lat','lon']])) # Conversione delle coordinate in radianti\n",
    "\n",
    "# Creazione di una matrice di distanze\n",
    "n_points = len(df_eco_rad)\n",
    "\n",
    "distance_matrix = np.zeros((n_points, n_points))\n",
    "for i in range(n_points):\n",
    "    for j in range(i, n_points):\n",
    "        distance_matrix[i, j] = haversine_distance(df_eco_rad[i][0], df_eco_rad[i][1], df_eco_rad[j][0], df_eco_rad[j][1])\n",
    "        distance_matrix[j, i] = distance_matrix[i, j]\n",
    "\n",
    "# now we can compute the optic algorithm\n",
    "scores_eco = []\n",
    "\n",
    "for i in min_sample_params:\n",
    "    \n",
    "    for j in min_cluster_size_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        optics = OPTICS(min_samples=i, \n",
    "                        xi=0.05, \n",
    "                        min_cluster_size=j, \n",
    "                        metric='precomputed')\n",
    "        \n",
    "        # fit to economic dataset\n",
    "        optics_eco = optics.fit(distance_matrix)\n",
    "        clusters_eco = optics_eco.labels_\n",
    "        num_clusters_eco = len(set(clusters_eco)) - 1 # to esclude the noise cluster\n",
    "        \n",
    "        if num_clusters_eco in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_eco_rad, clusters_eco)\n",
    "            davies_score = davies_bouldin_score(df_eco_rad, clusters_eco)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_eco, sil_score, davies_score)\n",
    "            scores_eco.append(score_valid)\n",
    "        \n",
    "scores_eco.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the optics found {len(scores_eco)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_eco:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e96faa",
   "metadata": {},
   "source": [
    "## education dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "180d0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optics found 5 valid results\n",
      "the result is:(2, 2, 14, 0.357300198824369, 1.2244185939615952)\n",
      "the result is:(2, 3, 10, 0.2238545846561928, 4.314385546032243)\n",
      "the result is:(3, 2, 10, 0.18993955767520576, 2.948702235071174)\n",
      "the result is:(3, 3, 10, 0.18993955767520576, 2.948702235071174)\n",
      "the result is:(2, 4, 7, 0.08312932079101602, 1.7758504239152286)\n"
     ]
    }
   ],
   "source": [
    "df_edu_rad = np.array(np.radians(df_edu[['lat','lon']])) # Conversione delle coordinate in radianti\n",
    "\n",
    "# Creazione di una matrice di distanze\n",
    "n_points = len(df_edu_rad)\n",
    "\n",
    "distance_matrix = np.zeros((n_points, n_points))\n",
    "for i in range(n_points):\n",
    "    for j in range(i, n_points):\n",
    "        distance_matrix[i, j] = haversine_distance(df_edu_rad[i][0], df_edu_rad[i][1], df_edu_rad[j][0], df_edu_rad[j][1])\n",
    "        distance_matrix[j, i] = distance_matrix[i, j]\n",
    "\n",
    "# now we can compute the optic algorithm\n",
    "scores_edu = []\n",
    "\n",
    "for i in min_sample_params:\n",
    "    \n",
    "    for j in min_cluster_size_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        optics = OPTICS(min_samples=i, \n",
    "                        xi=0.05, \n",
    "                        min_cluster_size=j, \n",
    "                        metric='precomputed')\n",
    "        \n",
    "        # fit to edunomic dataset\n",
    "        optics_edu = optics.fit(distance_matrix)\n",
    "        clusters_edu = optics_edu.labels_\n",
    "        num_clusters_edu = len(set(clusters_edu)) - 1 # to esclude the noise cluster\n",
    "        \n",
    "        if num_clusters_edu in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_edu_rad, clusters_edu)\n",
    "            davies_score = davies_bouldin_score(df_edu_rad, clusters_edu)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_edu, sil_score, davies_score)\n",
    "            scores_edu.append(score_valid)\n",
    "        \n",
    "scores_edu.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the optics found {len(scores_edu)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_edu:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8558e",
   "metadata": {},
   "source": [
    "## health dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d7165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optics found 1 valid results\n",
      "the result is:(2, 2, 7, -0.041298909616827396, 6.198425427325789)\n"
     ]
    }
   ],
   "source": [
    "df_hea_rad = np.array(np.radians(df_hea[['lat','lon']])) # Conversione delle coordinate in radianti\n",
    "\n",
    "# Creazione di una matrice di distanze\n",
    "n_points = len(df_hea_rad)\n",
    "\n",
    "distance_matrix = np.zeros((n_points, n_points))\n",
    "for i in range(n_points):\n",
    "    for j in range(i, n_points):\n",
    "        distance_matrix[i, j] = haversine_distance(df_hea_rad[i][0], df_hea_rad[i][1], df_hea_rad[j][0], df_hea_rad[j][1])\n",
    "        distance_matrix[j, i] = distance_matrix[i, j]\n",
    "\n",
    "# now we can compute the optic algorithm\n",
    "scores_hea = []\n",
    "\n",
    "for i in min_sample_params:\n",
    "    \n",
    "    for j in min_cluster_size_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        optics = OPTICS(min_samples=i, \n",
    "                        xi=0.05, \n",
    "                        min_cluster_size=j, \n",
    "                        metric='precomputed')\n",
    "        \n",
    "        # fit to heanomic dataset\n",
    "        optics_hea = optics.fit(distance_matrix)\n",
    "        clusters_hea = optics_hea.labels_\n",
    "        num_clusters_hea = len(set(clusters_hea)) - 1 # to esclude the noise cluster\n",
    "        \n",
    "        if num_clusters_hea in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_hea_rad, clusters_hea)\n",
    "            davies_score = davies_bouldin_score(df_hea_rad, clusters_hea)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_hea, sil_score, davies_score)\n",
    "            scores_hea.append(score_valid)\n",
    "        \n",
    "scores_hea.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the optics found {len(scores_hea)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_hea:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901606d",
   "metadata": {},
   "source": [
    "## shopping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "556a9a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optics found 4 valid results\n",
      "the result is:(2, 2, 14, 0.3055166662141259, 1.9975609116247335)\n",
      "the result is:(2, 3, 7, 0.12362215925071614, 2.0888125648532947)\n",
      "the result is:(3, 2, 7, 0.16775706350693606, 5.78588845870898)\n",
      "the result is:(3, 3, 7, 0.16775706350693606, 5.78588845870898)\n"
     ]
    }
   ],
   "source": [
    "df_shop_rad = np.array(np.radians(df_shop[['lat','lon']])) # Conversione delle coordinate in radianti\n",
    "\n",
    "# Creazione di una matrice di distanze\n",
    "n_points = len(df_shop_rad)\n",
    "\n",
    "distance_matrix = np.zeros((n_points, n_points))\n",
    "for i in range(n_points):\n",
    "    for j in range(i, n_points):\n",
    "        distance_matrix[i, j] = haversine_distance(df_shop_rad[i][0], df_shop_rad[i][1], df_shop_rad[j][0], df_shop_rad[j][1])\n",
    "        distance_matrix[j, i] = distance_matrix[i, j]\n",
    "\n",
    "# now we can compute the optic algorithm\n",
    "scores_shop = []\n",
    "\n",
    "for i in min_sample_params:\n",
    "    \n",
    "    for j in min_cluster_size_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        optics = OPTICS(min_samples=i, \n",
    "                        xi=0.05, \n",
    "                        min_cluster_size=j, \n",
    "                        metric='precomputed')\n",
    "        \n",
    "        # fit to shopnomic dataset\n",
    "        optics_shop = optics.fit(distance_matrix)\n",
    "        clusters_shop = optics_shop.labels_\n",
    "        num_clusters_shop = len(set(clusters_shop)) - 1 # to esclude the noise cluster\n",
    "        \n",
    "        if num_clusters_shop in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_shop_rad, clusters_shop)\n",
    "            davies_score = davies_bouldin_score(df_shop_rad, clusters_shop)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_shop, sil_score, davies_score)\n",
    "            scores_shop.append(score_valid)\n",
    "        \n",
    "scores_shop.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the optics found {len(scores_shop)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_shop:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e59301",
   "metadata": {},
   "source": [
    "## tourism dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f52663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optics found 9 valid results\n",
      "the result is:(2, 2, 16, 0.26664362834648003, 1.5662206762782789)\n",
      "the result is:(2, 3, 9, 0.0895406212794005, 4.606519264497488)\n",
      "the result is:(3, 2, 9, 0.17881723745864564, 1.5670347731316123)\n",
      "the result is:(3, 3, 9, 0.17881723745864564, 1.5670347731316123)\n",
      "the result is:(2, 4, 8, 0.15373673982717517, 1.7057287275232476)\n",
      "the result is:(3, 4, 7, 0.10380022186309074, 1.5349515001976153)\n",
      "the result is:(4, 2, 7, 0.28897795388755937, 1.647947327059121)\n",
      "the result is:(4, 3, 7, 0.28897795388755937, 1.647947327059121)\n",
      "the result is:(4, 4, 7, 0.28897795388755937, 1.647947327059121)\n"
     ]
    }
   ],
   "source": [
    "df_tou_rad = np.array(np.radians(df_tou[['lat','lon']])) # Conversione delle coordinate in radianti\n",
    "\n",
    "# Creazione di una matrice di distanze\n",
    "n_points = len(df_tou_rad)\n",
    "\n",
    "distance_matrix = np.zeros((n_points, n_points))\n",
    "for i in range(n_points):\n",
    "    for j in range(i, n_points):\n",
    "        distance_matrix[i, j] = haversine_distance(df_tou_rad[i][0], df_tou_rad[i][1], df_tou_rad[j][0], df_tou_rad[j][1])\n",
    "        distance_matrix[j, i] = distance_matrix[i, j]\n",
    "\n",
    "# now we can compute the optic algorithm\n",
    "scores_tou = []\n",
    "\n",
    "for i in min_sample_params:\n",
    "    \n",
    "    for j in min_cluster_size_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        optics = OPTICS(min_samples=i, \n",
    "                        xi=0.05, \n",
    "                        min_cluster_size=j, \n",
    "                        metric='precomputed')\n",
    "        \n",
    "        # fit to tounomic dataset\n",
    "        optics_tou = optics.fit(distance_matrix)\n",
    "        clusters_tou = optics_tou.labels_\n",
    "        num_clusters_tou = len(set(clusters_tou)) - 1 # to esclude the noise cluster\n",
    "        \n",
    "        if num_clusters_tou in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_tou_rad, clusters_tou)\n",
    "            davies_score = davies_bouldin_score(df_tou_rad, clusters_tou)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_tou, sil_score, davies_score)\n",
    "            scores_tou.append(score_valid)\n",
    "        \n",
    "scores_tou.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the optics found {len(scores_tou)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_tou:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f281f0cd",
   "metadata": {},
   "source": [
    "## catering  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f0357f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optics found 31 valid results\n",
      "the result is:(3, 8, 17, -0.13056528824436137, 4.231267681881338)\n",
      "the result is:(3, 9, 17, -0.11506471087226439, 4.524717848338473)\n",
      "the result is:(4, 7, 17, -0.1426207188973168, 5.071021404073162)\n",
      "the result is:(5, 7, 17, -0.12324357095392269, 3.4919799305153414)\n",
      "the result is:(6, 7, 17, -0.12718789695780078, 2.112624765305898)\n",
      "the result is:(7, 8, 16, -0.026803207946356124, 3.6179762091018066)\n",
      "the result is:(8, 2, 16, -0.025402189688466272, 2.63414647611268)\n",
      "the result is:(8, 3, 16, -0.025402189688466272, 2.63414647611268)\n",
      "the result is:(8, 4, 16, -0.025402189688466272, 2.63414647611268)\n",
      "the result is:(8, 5, 16, -0.025402189688466272, 2.63414647611268)\n",
      "the result is:(8, 6, 16, -0.025402189688466272, 2.63414647611268)\n",
      "the result is:(8, 7, 16, 0.04452750194589625, 3.139181118672527)\n",
      "the result is:(8, 8, 16, 0.04452750194589625, 3.139181118672527)\n",
      "the result is:(2, 8, 14, -0.24391510972448846, 2.9576185924650487)\n",
      "the result is:(2, 9, 14, -0.2114545468410698, 3.5929986312110898)\n",
      "the result is:(4, 8, 14, -0.19307442244037898, 3.37363137345466)\n",
      "the result is:(5, 8, 14, -0.16267989236320787, 2.4409505115976353)\n",
      "the result is:(8, 9, 14, 0.0025813490294197016, 2.834274262639688)\n",
      "the result is:(4, 9, 13, -0.19209768494179325, 4.050572002095771)\n",
      "the result is:(6, 8, 13, -0.19237975017485914, 2.1461753492489866)\n",
      "the result is:(7, 9, 13, -0.025149046931013955, 3.937230847282318)\n",
      "the result is:(9, 2, 13, -0.1478180528908083, 3.830089610129728)\n",
      "the result is:(9, 3, 13, -0.1478180528908083, 3.830089610129728)\n",
      "the result is:(9, 4, 13, -0.1478180528908083, 3.830089610129728)\n",
      "the result is:(9, 5, 13, -0.1478180528908083, 3.830089610129728)\n",
      "the result is:(5, 9, 12, -0.20724643209342625, 2.1275590612738906)\n",
      "the result is:(6, 9, 11, -0.18342588737931212, 2.341274900831946)\n",
      "the result is:(9, 6, 11, -0.16392798764057787, 4.140577937833113)\n",
      "the result is:(9, 7, 10, -0.17877759366365467, 2.8671766040976663)\n",
      "the result is:(9, 8, 10, -0.10878289680610058, 3.695025295600576)\n",
      "the result is:(9, 9, 10, -0.10878289680610058, 3.695025295600576)\n"
     ]
    }
   ],
   "source": [
    "df_cat_rad = np.array(np.radians(df_cat[['lat','lon']])) # Conversione delle coordinate in radianti\n",
    "\n",
    "# Creazione di una matrice di distanze\n",
    "n_points = len(df_cat_rad)\n",
    "\n",
    "distance_matrix = np.zeros((n_points, n_points))\n",
    "for i in range(n_points):\n",
    "    for j in range(i, n_points):\n",
    "        distance_matrix[i, j] = haversine_distance(df_cat_rad[i][0], df_cat_rad[i][1], df_cat_rad[j][0], df_cat_rad[j][1])\n",
    "        distance_matrix[j, i] = distance_matrix[i, j]\n",
    "\n",
    "# now we can compute the optic algorithm\n",
    "scores_cat = []\n",
    "\n",
    "for i in min_sample_params:\n",
    "    \n",
    "    for j in min_cluster_size_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        optics = OPTICS(min_samples=i, \n",
    "                        xi=0.05, \n",
    "                        min_cluster_size=j, \n",
    "                        metric='precomputed')\n",
    "        \n",
    "        # fit to catnomic dataset\n",
    "        optics_cat = optics.fit(distance_matrix)\n",
    "        clusters_cat = optics_cat.labels_\n",
    "        num_clusters_cat = len(set(clusters_cat)) - 1 # to esclude the noise cluster\n",
    "        \n",
    "        if num_clusters_cat in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_cat_rad, clusters_cat)\n",
    "            davies_score = davies_bouldin_score(df_cat_rad, clusters_cat)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_cat, sil_score, davies_score)\n",
    "            scores_cat.append(score_valid)\n",
    "        \n",
    "scores_cat.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the optics found {len(scores_cat)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_cat:\n",
    "    print(f\"the result is:{s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
