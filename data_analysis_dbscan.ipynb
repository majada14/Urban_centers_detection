{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189d9441",
   "metadata": {},
   "source": [
    "# import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159f3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# statistic libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "#from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d72e5",
   "metadata": {},
   "source": [
    "# load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fad383d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265590160</td>\n",
       "      <td>46.047611</td>\n",
       "      <td>11.126020</td>\n",
       "      <td>Volksbank</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269193707</td>\n",
       "      <td>46.074491</td>\n",
       "      <td>11.124553</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269193731</td>\n",
       "      <td>46.064718</td>\n",
       "      <td>11.123213</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288910331</td>\n",
       "      <td>46.065631</td>\n",
       "      <td>11.154994</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292015813</td>\n",
       "      <td>46.076473</td>\n",
       "      <td>11.141931</td>\n",
       "      <td>Cassa di Trento</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        lat        lon             name     class\n",
       "0  265590160  46.047611  11.126020        Volksbank  economic\n",
       "1  269193707  46.074491  11.124553  Cassa di Trento  economic\n",
       "2  269193731  46.064718  11.123213  Cassa di Trento  economic\n",
       "3  288910331  46.065631  11.154994  Cassa di Trento  economic\n",
       "4  292015813  46.076473  11.141931  Cassa di Trento  economic"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('/Users/majadallacqua/Desktop/universit√†/II_sem/CSS/urban analysis/data/trento_poi_dataset.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc8bdd",
   "metadata": {},
   "source": [
    "# set the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cfe1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms_per_radian = 6371.0088\n",
    "\n",
    "# 12 is the number of districts in the city of Trento\n",
    "min_neigh = 12 - 5 # value for the city of Trento\n",
    "max_neigh = 12 + 5\n",
    "\n",
    "# subset used for each analysis\n",
    "df_eco = df[df['class']=='economic']\n",
    "df_edu = df[df['class']=='education']\n",
    "df_hea = df[df['class']=='health']\n",
    "df_cat = df[df['class']=='catering']\n",
    "df_shop = df[df['class']=='shopping']\n",
    "df_tou = df[df['class']=='tourism']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cb90a",
   "metadata": {},
   "source": [
    "# DBSCAN algorithm\n",
    "we don't have many data points in this dataset.\n",
    "We don't expect many banks being very close, this may happen in the city's center but not in all the municipality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0932ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's the value we want to try\n",
    "eps_params = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7] # metric is in km\n",
    "min_params = [2, 3, 4, 5, 6, 7, 8, 9] # min number of elements we want in each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f03579",
   "metadata": {},
   "source": [
    "## economic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124e8bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dbscan found 4 valid results\n",
      "the result is:(0.2, 2, 12, 0.24726358874225482, 3.621104992985061)\n",
      "the result is:(0.1, 2, 9, -0.14614024445658866, 3.6028257040145943)\n",
      "the result is:(0.3, 2, 9, 0.32082015139421943, 2.998499146462305)\n",
      "the result is:(0.3, 3, 7, 0.2204072771380088, 6.049514547338348)\n"
     ]
    }
   ],
   "source": [
    "df_eco_rad = np.radians(df_eco[['lat','lon']])\n",
    "scores_eco = []\n",
    "\n",
    "for i in eps_params:\n",
    "    \n",
    "    epsilon = i / kms_per_radian\n",
    "    \n",
    "    for j in min_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        dbscan = DBSCAN(eps=epsilon, \n",
    "                min_samples=j,\n",
    "                algorithm = 'ball_tree',\n",
    "                metric='haversine')\n",
    "        \n",
    "        # fit to economic dataset\n",
    "        db_eco = dbscan.fit(df_eco_rad)\n",
    "        clusters_eco = db_eco.labels_\n",
    "        num_clusters_eco = len(set(clusters_eco)) - 1 # to esclude the noise cluster\n",
    "        \n",
    "        if num_clusters_eco in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_eco_rad, clusters_eco)\n",
    "            davies_score = davies_bouldin_score(df_eco_rad, clusters_eco)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_eco, sil_score, davies_score)\n",
    "            scores_eco.append(score_valid)\n",
    "        \n",
    "scores_eco.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the dbscan found {len(scores_eco)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_eco:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2b986",
   "metadata": {},
   "source": [
    "## education dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5e88b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dbscan found 5 valid results\n",
      "the result is:(0.2, 2, 9, -0.052260926345964416, 7.037638332931813)\n",
      "the result is:(0.3, 2, 8, 0.07659342420441541, 4.76102488311645)\n",
      "the result is:(0.5, 2, 8, 0.2791108468328062, 2.471357161117928)\n",
      "the result is:(0.3, 3, 7, 0.0441339731907586, 7.046563074574154)\n",
      "the result is:(0.6, 2, 7, 0.2703153552098291, 2.8328851628044274)\n"
     ]
    }
   ],
   "source": [
    "df_edu_rad = np.radians(df_edu[['lat','lon']])\n",
    "scores_edu = []\n",
    "\n",
    "for i in eps_params:\n",
    "    \n",
    "    epsilon = i / kms_per_radian\n",
    "    \n",
    "    for j in min_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        dbscan = DBSCAN(eps=epsilon, \n",
    "                min_samples=j,\n",
    "                algorithm = 'ball_tree',\n",
    "                metric='haversine')\n",
    "        \n",
    "        # fit to education dataset\n",
    "        db_edu = dbscan.fit(df_edu_rad)\n",
    "        clusters_edu = db_edu.labels_\n",
    "        num_clusters_edu = len(set(clusters_edu)) - 1\n",
    "        \n",
    "        if num_clusters_edu in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_edu_rad, clusters_edu)\n",
    "            davies_score = davies_bouldin_score(df_edu_rad, clusters_edu)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_edu, sil_score, davies_score)\n",
    "            scores_edu.append(score_valid)\n",
    "        \n",
    "scores_edu.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the dbscan found {len(scores_edu)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_edu:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147cbbd",
   "metadata": {},
   "source": [
    "## health dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acbbebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dbscan found 3 valid results\n",
      "the result is:(0.4, 2, 3, -0.05649395027515204, 5.599380761918972)\n",
      "the result is:(0.6, 2, 3, 0.22780805424024034, 4.747780158289724)\n",
      "the result is:(0.7, 2, 3, 0.2403984775267705, 5.292712890204045)\n"
     ]
    }
   ],
   "source": [
    "df_hea_rad = np.radians(df_hea[['lat','lon']])\n",
    "scores_hea = []\n",
    "\n",
    "for i in eps_params:\n",
    "    \n",
    "    epsilon = i / kms_per_radian\n",
    "    \n",
    "    for j in min_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        dbscan = DBSCAN(eps=epsilon, \n",
    "                min_samples=j,\n",
    "                algorithm = 'ball_tree',\n",
    "                metric='haversine')\n",
    "        \n",
    "        # fit to health dataset\n",
    "        db_hea = dbscan.fit(df_hea_rad)\n",
    "        clusters_hea = db_hea.labels_\n",
    "        num_clusters_hea = len(set(clusters_hea)) - 1\n",
    "        \n",
    "        if num_clusters_hea in range(min_neigh - 4, max_neigh + 4):\n",
    "            sil_score = metrics.silhouette_score(df_hea_rad, clusters_hea)\n",
    "            davies_score = davies_bouldin_score(df_hea_rad, clusters_hea)\n",
    "                                     \n",
    "            score_valid = (i, j, num_clusters_hea, sil_score, davies_score)\n",
    "            scores_hea.append(score_valid)\n",
    "        \n",
    "scores_hea.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the dbscan found {len(scores_hea)} valid results\") # use this to check how many items have been saved \n",
    "for s in scores_hea:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2631b9",
   "metadata": {},
   "source": [
    "## catering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3dcccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dbscan found 18 valid results\n",
      "the result is:(0.2, 3, 17, 0.11005478139924929, 2.854424399773766)\n",
      "the result is:(0.3, 3, 17, 0.24788966815184907, 2.402072306180986)\n",
      "the result is:(0.4, 3, 16, 0.3240079446943718, 2.0540389448973624)\n",
      "the result is:(0.1, 3, 14, -0.09674402633281363, 5.336195091189466)\n",
      "the result is:(0.7, 2, 14, 0.23760706795339004, 1.7039293686965915)\n",
      "the result is:(0.5, 3, 13, 0.379215225382933, 1.9324076556519234)\n",
      "the result is:(0.6, 3, 12, 0.39180705994585097, 2.6867603348261224)\n",
      "the result is:(0.4, 4, 10, 0.2773263779642477, 3.9727119705462184)\n",
      "the result is:(0.7, 3, 10, 0.37181588287959577, 2.2583013472566744)\n",
      "the result is:(0.1, 4, 9, -0.1487552407689662, 16.689508895997825)\n",
      "the result is:(0.2, 4, 9, 0.08738413435015968, 6.005604105829745)\n",
      "the result is:(0.5, 4, 8, 0.35566582914876355, 3.9993265546474976)\n",
      "the result is:(0.2, 5, 7, 0.022409370187647708, 13.825475632429491)\n",
      "the result is:(0.2, 6, 7, 0.0088780890362644, 11.154171198529616)\n",
      "the result is:(0.3, 4, 7, 0.32427096872384, 13.8142928943913)\n",
      "the result is:(0.5, 5, 7, 0.3416784565451901, 5.851060946553275)\n",
      "the result is:(0.6, 4, 7, 0.3605783373221165, 2.436457615035385)\n",
      "the result is:(0.6, 5, 7, 0.3594433683696255, 3.2762616349471085)\n"
     ]
    }
   ],
   "source": [
    "df_cat_rad = np.radians(df_cat[['lat','lon']])\n",
    "scores_cat = []\n",
    "\n",
    "for i in eps_params:\n",
    "    \n",
    "    epsilon = i / kms_per_radian\n",
    "    \n",
    "    for j in min_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        dbscan = DBSCAN(eps=epsilon, \n",
    "                min_samples=j,\n",
    "                algorithm = 'ball_tree',\n",
    "                metric='haversine')\n",
    "        \n",
    "        # fit to catering dataset\n",
    "        db_cat = dbscan.fit(df_cat_rad)\n",
    "        clusters_cat = db_cat.labels_\n",
    "        num_clusters_cat = len(set(clusters_cat)) - 1\n",
    "        \n",
    "        if num_clusters_cat in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_cat_rad, clusters_cat)\n",
    "            davies_score = davies_bouldin_score(df_cat_rad, clusters_cat)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_cat, sil_score, davies_score)\n",
    "            scores_cat.append(score_valid)\n",
    "        \n",
    "scores_cat.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the dbscan found {len(scores_cat)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_cat:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ea9eb",
   "metadata": {},
   "source": [
    "## shopping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9e14c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dbscan found 2 valid results\n",
      "the result is:(0.4, 2, 8, -0.017548109117090132, 3.7247715031057576)\n",
      "the result is:(0.5, 2, 8, 0.04463992489948266, 3.1825381201422194)\n"
     ]
    }
   ],
   "source": [
    "df_shop_rad = np.radians(df_shop[['lat','lon']])\n",
    "scores_shop = []\n",
    "\n",
    "for i in eps_params:\n",
    "    \n",
    "    epsilon = i / kms_per_radian\n",
    "    \n",
    "    for j in min_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        dbscan = DBSCAN(eps=epsilon, \n",
    "                min_samples=j,\n",
    "                algorithm = 'ball_tree',\n",
    "                metric='haversine')\n",
    "        \n",
    "        # fit to shopnomic dataset\n",
    "        db_shop = dbscan.fit(df_shop_rad)\n",
    "        clusters_shop = db_shop.labels_\n",
    "        num_clusters_shop = len(set(clusters_shop)) - 1\n",
    "        \n",
    "        if num_clusters_shop in range(min_neigh, max_neigh +1):\n",
    "            sil_score = metrics.silhouette_score(df_shop_rad, clusters_shop)\n",
    "            davies_score = davies_bouldin_score(df_shop_rad, clusters_shop)\n",
    "\n",
    "            score_valid = (i, j, num_clusters_shop, sil_score, davies_score)\n",
    "            scores_shop.append(score_valid)\n",
    "        \n",
    "scores_shop.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the dbscan found {len(scores_shop)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_shop:\n",
    "    print(f\"the result is:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de42b4",
   "metadata": {},
   "source": [
    "## tourism dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f8ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dbscan found 6 valid results\n",
      "the result is:(0.2, 2, 12, 0.1074743667167245, 1.6418871658521113)\n",
      "the result is:(0.3, 2, 8, 0.17172268032513446, 1.5047089773721372)\n",
      "the result is:(0.6, 2, 8, 0.4629136719343527, 1.2447038136381723)\n",
      "the result is:(0.1, 2, 7, -0.17275846970609915, 2.819913143845101)\n",
      "the result is:(0.5, 2, 7, 0.4599598040559525, 1.0966628542874715)\n",
      "the result is:(0.7, 2, 7, 0.47275006069814923, 1.2034767990991755)\n"
     ]
    }
   ],
   "source": [
    "df_tou_rad = np.radians(df_tou[['lat','lon']])\n",
    "scores_tou = []\n",
    "\n",
    "for i in eps_params:\n",
    "    \n",
    "    epsilon = i / kms_per_radian\n",
    "    \n",
    "    for j in min_params:\n",
    "        \n",
    "        # general parameters for the DBSCAN algorithm\n",
    "        dbscan = DBSCAN(eps=epsilon, \n",
    "                min_samples=j,\n",
    "                algorithm = 'ball_tree',\n",
    "                metric='haversine')\n",
    "        \n",
    "        # fit to tounomic dataset\n",
    "        db_tou = dbscan.fit(df_tou_rad)\n",
    "        clusters_tou = db_tou.labels_\n",
    "        num_clusters_tou = len(set(clusters_tou)) - 1\n",
    "        \n",
    "        if num_clusters_tou in range(min_neigh, max_neigh + 1):\n",
    "            sil_score = metrics.silhouette_score(df_tou_rad, clusters_tou)\n",
    "            davies_score = davies_bouldin_score(df_tou_rad, clusters_tou)\n",
    "\n",
    "\n",
    "            score_valid = (i, j, num_clusters_tou, sil_score, davies_score)\n",
    "            scores_tou.append(score_valid)\n",
    "        \n",
    "scores_tou.sort(key=lambda tuple: tuple[2], reverse=True)     \n",
    "\n",
    "# let's print the results to compare them:\n",
    "print(f\"the dbscan found {len(scores_tou)} valid results\") # use this to check how many items have been saved    \n",
    "for s in scores_tou:\n",
    "    print(f\"the result is:{s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
